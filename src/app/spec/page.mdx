
# Iroh Specfication

<Note>
  <h1 className="bold text-lg">UNFINISHED</h1>
  <p>This is very much a work in progress. Don't consider it accurate until this warning is removed.</p>
</Note>

# Overview

# Connections

At the core of iroh is a network where any two nodes within the network can establish a connection. {{className: 'lead'}}

## Nodes

An iroh network is a collection of _nodes_. A node is a running process that might accept connections from other nodes on a given port. Multiple nodes can be run on the same physical device, but not the same port.

A node has a cryptographic keypair used for signing messages. Nodes are uniquely identified by the public portion of their keypair.

## Connections

Iroh uses [QUIC](https://en.wikipedia.org/wiki/QUIC) as a transport layer networking protocol.

- QUIC
  - UDP
  - Avoids multiplexing overhead
  - 0-RTT handshakes

## MagicSockets

Connections in iroh have a _MagicSocket_ sitting between QUIC and the operating system socket (the "real socket"). The MagicSocket simulates a connection for the quic transport, and dynamically optimizes the connection path between two nodes as connections are negotiated & optimized. The MagicSocket will perform _interactive connectivity establishment_ (ICE), using an advertised set of connection details to audition connections. The magicsocket will perform latency probes for any viable connections, switching to find the fastest ping.

Establishing direct connections between

## Relays

Sometimes it isn't possible to establish a direct connection between two nodess, often because of strict firewall rules or NAT configurations. In these cases the only fallback is to _relay_ traffic through a third node that both nodes can connect to. Instead of sending packets directly from one node to the other, packets in either direction are first sent to the relay node, which forwards packets on to their destination.

MagicSockets 

All QUIC traffic is encrypted, and relayed traffic is no exception. The relaying server _cannot_ inspect the contents of the packets being forwarded, 

## Anchors

Anchors are highly available nodes that are reliably online (that is, they're online most of the time). These are servers in a traditional server-client setup, but in the context of iroh they have no 

## Protocols

ALPN-per-protocol

## MagicSock

The API is centered around the “MagicSocket” or `MagicSock`. Iroh creates a `MagicSock` and uses that socket as an `AsycnUdpSocket` in a `quinn::Endpoint`. All the connection/hole punching work happens inside of the `MagicSock`. As far as QUIC is concerned, all of the packets going in and out of the `quinn::Endpoint` are being sent over UDP.

In reality, the `Magicsock` binds an IPv4 and IPv6 UDP socket. It also spins up a DERP Client for each DERP server we are configured to connect with over HTTP/HTTPS. You need to be connected to at least one Derper (DERP + STUN server) in order to do any hole punching.

To dial a peer, you must first add the peer to `MagicSock` explicitly via its public key (and any known addresses) and get a “mapped address” in return, which is an IPv6 Unique Local Address with a fixed Global ID and Subnet ID to easily identify it as such. This mapped address is what you pass to the quinn::Endpoint in order to dial that per. This ensures we are able to dial via a public key.

Each time you send packets to a particular peer, the `MagicSock` will request the `best_addr` from its internal peer address book. This means the address and socket on which we send the latest packet may be different from the one we sent previously.

We are also listening for incoming packets on all of these sockets, and pass up any QUIC packets back up to the `quinn::Endpoint`

## Finding the “best addr”

When we first create a `MagicSock`, our first step to connectivity is to understand our own networking situation. We do an investigation into all of our own network interfaces and capabilities.

Then, we start a  netcheck report, which attempts to figure out all of our public facing details by doing:

- A STUN requests sent to the Derper (IPv4 & IPv6)
- Hair pinning probe
- Port mapping probe
- Captive portal discovery

Once we’ve gathered all the appropriate information, we are ready to connect.

To connect to another peer, we at minimum need to know it’s public key and its “DERP Region”. A DERP Region is a group of DERP Servers that are all meshed together, and can act as packet forwarders for each other. Each iroh node is expected to have a “home” DERP region that it maintains a connection to.

If we have a list of possible addresses for the node to which we want to connect, that’s even better!

We add those addresses, and the peer’s PublicKey, to the `MagicSock` peer address book. When we attempt to send packets to that peer, we assess the options in the address book for the `best_addr` (UDP address) to send the packets on. An address is a viable `best_addr` if we have sent a ping on that address, and received a pong in return. This lets us know that we can actually communicate on that address and the latency when using that address. The `best_addr` has the lowest latency. If there is no `best_addr` (because we have not received a pong, or because the latency has “expired”) we also send all packets to the peer’s DERP region” to ensure that the packets go through.

If we don’t have a `best_addr` , we start the `Disco` process and try to hole punch.

## DERP & Disco

If we have not attempted to hole punch to that peer, it’s been a while since we’ve last attempted, or we only have a DERP address and no direct UDP address, we do the hole punching dance, which in our world is referred to as a `Disco::CallMeMaybe` request.

- Disco messages are encrypted. You must have the PublicKey of the remote peer in order to send a Disco message.
- A `Disco::CallMeMaybe` request includes a list of your own public addresses, that you want the remote peer to attempt to dial.
- `Disco::CallMeMaybe` requests are only ever sent over the DERP relay servers
- At the same time as the `Disco::CallMeMaybe` message is sent, we also send `Disco::Ping` messages to any known UDP addresses of the remote peer
- If the remote server is able to receive any of the `Disco::Ping` messages, it sends a return `Disco::Pong`, telling the node that that particular address is a viable address to communicate over UDP
- When the remote server gets a `Disco::CallMeMaybe` request, it can choose to respond to it with its own `Disco::CallMeMaybe` and `Disco::Pings` on all the given addresses. It will not respond if it has never encountered this `PublicKey` before.
- These `ping`/ `pong`messages are what do the actual hole punching, and the `CallMeMaybe` messages are what coordinates them.

If at any time during our transmission of packets, we receive a `Pong` from the remote peer, our internal record of the addresses and endpoints for that peer is updated with the new latency information. The next time we request the “best address” for that remote peer, we can switch to sending packets on a different address, with the better latency.

We check latency (by sending new `Disco::Ping` messages) about once a minute

If no hole punching ever occurs, we continue to use the fallback of relaying the packets over the DERP servers.

![intg_derper__1_to_1_NAT_both.svg](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/8b772f04-c2bf-4fa1-807f-6e86d980f3b0/intg_derper__1_to_1_NAT_both.svg)


---

# Blobs


## Content Addressed Blobs

Iroh works with _blobs_ of opaque data, which are often the bytes of a file. Blobs can be of arbitrary size ranging from 0-u64MAX bytes.

All blobs within Iroh are referred to by the BLAKE3 [1] hash of contents. BLAKE3 is a _tree hashing_ algorithm, that splits its input into uniform chunks and arranges them as the leaves of a binary tree, producing intermediate _chunk hashes_ that accumulate up to a _root hash._ Iroh uses the 32 byte root hash (or just “hash”) as an immutable blob identifier. 

<img className="figure" src="/diagrams/fig_1_blob.svg" />

We leverage the tree hash structure of BLAKE3 as a basis for incremental verification when data is sent over the network, as described by Section 6.4 “Verified Streaming” in [1] and implemented in [2]. Iroh caches all chunk hashes as external metadata, leaving the unaltered input blob as the canonical source of bytes. Verified streaming also facilitates _range requests:_ fetching a verifiable contiguous subsequence of a blob by streaming only the portions of the BLAKE3 binary tree required to verify the designated subsequence.

Chunk hashes are distinct from root hashes, and only used during data transfer. The chunk size of BLAKE3 is a tunable constant that defaults to 1KiB, which results in a 6% overhead on on the size of the input blob. Increasing the chunk size reduces overhead, at the cost of requiring more data transfer before an incremental verification checkpoint is reached. The chunk size constant can be modified & recalculated *without affecting the root hash.* This opens the door to experiment with different chunk size constants, even at runtime. We intend to investigate chunk size optimization in future work.

Root hashes are expressed as a Content identifier (CID) as defined in [3], making Iroh an *IPFS system* capable of interoperating with other systems that use CIDs. In contrast to other IPFS systems, only root hashes are valid content identifiers, which enforces a strict 1-1 relationship between a Content Identifier and blob. This 1-1 relationship brings Iroh into alignment with common whole-file checksum systems. A naive implementation of Iroh can skip verified streaming entirely and use the the CID as a whole-file checksum.

## Collections

A *Collection* is an ordered set of named *links* to blobs. Collection link counts can range from 0-billions. Collections are the only means of relating blobs within iroh, and form the basis of synchronization & querying. Collections are true sets, and should not be nested to form graphs. The serialization format of a collection can be overridden with a user-provided dedoder.

## Default Collection Format

A link is a triple of `name, CID`. *Name* is an opaque, arbitrary sequence of bytes that labels the link. These are typically UTF-8 strings, but are always treated and sorted as bytes. Names must be unique across the collection, and order the set. *CID* is the content identifier for the linked blob.

Collections have an optional _header_ section that stores the number of items in the collection and offsets to items within the list, forming a skip list index.

<img className="figure" src="/diagrams/fig_2_collection.svg" />

Collections are content addressed in the exact same manner as blobs, but use differing CID multicodec identifier to distinguish them from opaque blobs. Like blobs, collections can be seeked into using byte offsets.

## Data Transfer Protocol

# High Level Description

The `n0/iroh/1` protocol is used to transfer collections of blobs from a *provider* to a *getter*.

- The *provider* takes the server role and accepts incoming connections.
- The *getter* takes the client role and initiates a connection which can make one or more requests
- Each request-response uses a separate QUIC stream.
- The request is the Blake3 hash of the desired **collection of blobs**.
- The *provider* responds by sending the collection metadata as a bao verified stream.  This metadata contains the hash of each blob contained in the collection.
- The *provider* sends each blob of the collection in sequence.  Each blob is sent as a small metadata structure and a bao verified stream of the contents.

# Protocol

## Transport

The `n0/iroh/1` protocol uses QUIC as network transport.

## Connection Establishment

Both the *getter* and *provider* use `n0/iroh/1` as ALPN.

Both the getter and provider generate a ed25519 keypair and use a variation of the [libp2p TLS handshake](https://github.com/libp2p/specs/blob/master/tls/tls.md) to generate and verify TLS certificates.


## Message Encodings

### Framing

The protocol makes use of *length-prefixed* message framing.

- The length prefix is written as a `u64` in **little endian** byte order.
- The length indicates the number of bytes in the message frame, excluding the length-prefix itself.

### Data Encoding

While some messages contain raw blob data, when messages contain other data which need to be encoded and decoded.  For this [the Postcard Wire Specification](https://postcard.jamesmunns.com/) is used.

## Request Handling

Each request from the *getter* must be in a new QUIC bi-directional stream.

### Handshake Message

The first message of each request is a `Handshake` message sent by the *getter*:

```rust
struct Handshake {
    version: u64,
    token: AuthToken,
}

struct AuthToken {
    bytes: [u8; 32]
}
```

- `version` is set to `1` indicating this protocol.
- `token` are some random bytes used to authenticate the *getter* to the *provider*.  The *provider* could use this to only allow requests from authorised tokens.

The message is sent as a Postcard-encoded length-prefixed frame as described in [Data Encoding](https://www.notion.so/Data-Encoding-bacc8298c5be4c56b100dd08c3391ad6).

### Request Message

The second message in the stream is the request, sent by the getter:

```rust
struct Request {
    name: Hash
}

struct Hash([u8; 32])
```

- `name` contains the Blake3 hash of the collection requested.

The message is sent as a Postcard-encoded length-prefixed frame as described in [Data Encoding](https://www.notion.so/Data-Encoding-bacc8298c5be4c56b100dd08c3391ad6).

After having sent the request the *getter* should finish the send-half of the stream, signalling that no more data will be sent over it.  The *provider* should read to the end of this stream.

## Response Handling

After receiving the request, the *provider* sends a first response message.  This either indicates the collection is available and will be returned, or it was not available.  The response message looks like this:

```rust
struct Response {
    data: Res,
}

struct Res {
    NotFound,
    Found,
    FoundCollection {
        total_blobs_size: u64,
    }
}
```

- `NotFound` means the *provider* does not have the requested item, this is used for both blobs (see later) or collections.
- `Found` is only used for transferring blobs to the client, see later.
- `FoundCollection` is used in the first response message if the collection can be transferred.
- `total_blobs_size` indicates the sum of all the raw sizes of the blobs in the collection.  This is not the same as the size that will flow over the network due to encoding overheads.

The message is sent as a Postcard-encoded length-prefixed frame as described in [Data Encoding](https://www.notion.so/Data-Encoding-bacc8298c5be4c56b100dd08c3391ad6).

### Collection Not Found

If a collection is not found the *provider* responds with a `Res::NotFound` message wrapped in a `Response`.  After this it finishes it’s send-half of the stream.  It can now close the stream as it is fully done.

The *getter* should read to the end of the stream.

### Collection Found

If a collection is available the *provider* responds with a `Res::FoundCollection` message wrapped in a `Response`.

### Collection Payload

After the *provider* sent the `Res::FoundCollection` message it sends the **bao encoded** collection metadata.  This is **not** sent as a length-prefixed message but directly as the bao **Combined Encoding Format**.  The client must read to the end of this bao data and can verify it using the hash it sent in the request.

Once the collection payload is decoded from the bao encoding it can be decoded using postcard and contains:

```rust
struct Collection {
    name: String,
    blobs: Vec<Blob>,
    total_blobs_size: u64,
}

struct Blob {
    name: String,
    hash: Hash,
}
```

- `Collection::name`contains an arbitrary name for the collection.  Not used by the protocol.
- `blobs` contains an **ordered** sequence of blobs in the collection.  Blobs can be referred to by their index in this sequence.
- `total_blobs_size` indicates the sum of all the raw sizes of the blobs in the collection.  This is not the same as the size that will flow over the network due to encoding overheads.
- `Blob::name` contains an arbitrary name for the blob.  Not used by the protocol.
- `hash` contains the Blake3 hash of the blob.

### Blob Messages

Next, the *provider* sends all the blobs in the collection on the stream.  Blobs are sent in the order they appear in the `Collection` structure.  For each blob two items are sent:

- A framed `Response` message with the `Res::Found` item as described here: [https://www.notion.so/number-zero/n0-iroh-1-network-protocol-f4f6d840f82e413f98dfc7bae527f3ec?pvs=4#d184b709cbd74bd1b1f4f04f0e062bac](https://www.notion.so/n0-iroh-1-network-protocol-f4f6d840f82e413f98dfc7bae527f3ec)
- The blob payload.  **Not* snt as a length-prefixed message but directly as the boa Combined Encoding Format.  The client must read to the end of this bao data and can verify it using the hash extracted from the collection metadata.

During sending a *provider* could discover does not have the data for one of the blobs.  In this case it will send a `Response` containing `Res::NotFound` instead of `Res::Found`.  After that it will finish the stream and not send further blobs.


## Storage

---

# Documents

Authors create and join documents: mutable key-value stores that multiple users read from, write to, and sync with, subscribing to live updates in real time. {{className: 'lead'}}

## Key-Value

## Permissioned

## Authors

## Multiple Writers

## Collaging

## Subscriptions

## Set Reconciliation

## Revocations & Key Rotations

## Document Querying

Queries can be performed to animate collection sets into graph structures. A typical example is constructing file system directories from the set using slash separators combined with a prefix query. We have yet to begin researching collection querying and will have more to report in the future, but know that prefix querying will be supported at a minimum.


---

# References

1. **IPFS**<br />
[https://github.com/ipfs/ipfs/blob/master/ipfs-p2p-file-system.pdf](https://github.com/ipfs/ipfs/blob/master/ipfs-p2p-file-system.pdf)
1. **CID (Content IDentifier): Self-describing content-addressed identifiers for distributed systems**<br />
[https://github.com/multiformats/cid](https://github.com/multiformats/cid)
1. **blake3**<br />
[https://github.com/BLAKE3-team/BLAKE3-specs/blob/master/blake3.pdf](https://github.com/BLAKE3-team/BLAKE3-specs/blob/master/blake3.pdf)
1. **bao**<br />
[https://github.com/oconnor663/bao](https://github.com/oconnor663/bao)
1. **QUIC: A UDP-Based Multiplexed and Secure Transport**<br />
[https://datatracker.ietf.org/doc/html/rfc9000](https://datatracker.ietf.org/doc/html/rfc9000)
1. **Tailscale**<br />
[https://tailscale.com/kb/tech-overviews/](https://tailscale.com/kb/tech-overviews/)
1. **Edwards-Curve Digital Signature Algorithm (EdDSA)**<br />
[https://datatracker.ietf.org/doc/html/rfc8032](https://datatracker.ietf.org/doc/html/rfc8032)
1. **earthstar**<br />
[https://earthstar-project.org/specs/data-spec-es5](https://earthstar-project.org/specs/data-spec-es5)
1. **Transport Layer Security (TLS) Application-Layer Protocol Negotiation Extension** <br />
[https://datatracker.ietf.org/doc/html/rfc7301](https://datatracker.ietf.org/doc/html/rfc7301)
4. **libp2p TLS handshake:**<br />
[https://github.com/libp2p/specs/blob/master/tls/tls.md](https://github.com/libp2p/specs/blob/master/tls/tls.md)
5. **The Postcard Wire Specification:**<br />
[https://postcard.jamesmunns.com/](https://postcard.jamesmunns.com/)
1. **willow**<br />
1. **Range-Based Set Reconciliation**<br />
1. **plumTree** <br />
1. **HyParView** <br />
